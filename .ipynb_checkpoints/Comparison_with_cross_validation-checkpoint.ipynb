{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "a_list = [32,42,13]\n",
    "print(len(a_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select features: V1 ~ V28 and Amount\n",
    "# Select target: Class\n",
    "features = ['Amount'] + ['V%d' % index for index in range(1, 29)]\n",
    "target = 'Class'\n",
    "\n",
    "# raw data X and y\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trick\n"
     ]
    }
   ],
   "source": [
    "# Normalize values for each feature, because there are many features with wide range of values\n",
    "# We need to get them in the equivalent range. Make the distribution of each values on the same scale.\n",
    "# Normalization procedure: (value - mean)/std\n",
    "# Normalization has to be done after split individually on both train and test sets.\n",
    "# Scaled data has zero mean and unit variance:\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# min_max_scalar = MinMaxScaler()\n",
    "def nomalization(X):\n",
    "    for feature in X.columns:\n",
    "        X[feature] -= X[feature].mean()\n",
    "        X[feature] /= X[feature].std()\n",
    "    return X\n",
    "print('trick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "0.970337911856\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     71079\n",
      "          1       0.04      0.62      0.07       123\n",
      "\n",
      "avg / total       1.00      0.97      0.98     71202\n",
      "\n",
      "0.999002822994\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71078\n",
      "          1       0.76      0.62      0.68       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71201\n",
      "\n",
      "mean and std: 0.9846703674252337, 0.020269153047542513\n",
      "1\n",
      "Round 2\n",
      "0.996053481644\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.28      0.85      0.43       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n",
      "0.999044970647\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     71079\n",
      "          1       0.82      0.57      0.67       123\n",
      "\n",
      "avg / total       1.00      1.00      1.00     71202\n",
      "\n",
      "mean and std: 0.9911097967852833, 0.01391854961822369\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 1. Define a model\n",
    "# 2. Stratified K-Folds cross-validator maintains percentage of samples for each class.\n",
    "# 3. Random_state = none ensures the results is replicable.\n",
    "# n_splits: how many times we want to split the data.\n",
    "\n",
    "# We test on a series of models.\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# model = KNeighborsClassifier()\n",
    "# model = RandomForestClassifier()\n",
    "# model = AdaBoostClassifier()\n",
    "# model = SVC() \n",
    "i = 0\n",
    "\n",
    "models = [] # to hold all the temporary models.\n",
    "model_scores = [] # to hold the accuracy scores \n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "for train_indices_out, test_indices_out in skf.split(X, y):\n",
    "    i+=1\n",
    "    # train/test split - outer loop.\n",
    "    X_train_out = X.loc[train_indices_out] \n",
    "    y_train_out = y.loc[train_indices_out]\n",
    "    \n",
    "    X_test_out = X.loc[test_indices_out]\n",
    "    y_test_out = y.loc[test_indices_out]\n",
    "    \n",
    "    print(\"Round {}\".format(i))\n",
    "    \n",
    "    for train_indices_in, test_indices_in in skf.split(X_train_out, y_train_out):\n",
    "\n",
    "        # train/test split - inner loop.\n",
    "        X_train_in = X_train_out.iloc[train_indices_in] \n",
    "        y_train_in = y_train_out.iloc[train_indices_in]\n",
    "    \n",
    "        X_test_in = X_train_out.iloc[test_indices_in]\n",
    "        y_test_in = y_train_out.iloc[test_indices_in]\n",
    "        \n",
    "        # Fit\n",
    "        model.fit(X_train_in, y_train_in)\n",
    "    \n",
    "        # Add to the model list.\n",
    "        models.append(model)\n",
    "    \n",
    "        # Predict\n",
    "        y_pred_in = model.predict(X_test_in)\n",
    "\n",
    "        # Show results\n",
    "        accuracy_in = accuracy_score(y_test_in, y_pred_in)\n",
    "        cm_in = classification_report(y_test_in, y_pred_in)\n",
    "        \n",
    "        model_scores.append(accuracy_in)\n",
    "        models.append(model)        \n",
    "\n",
    "        print(accuracy)\n",
    "        print(cm)\n",
    "    \n",
    "    # Calculate the mean and std_dev of the accuracy scores.\n",
    "    mean = statistics.mean(model_scores)\n",
    "    std = statistics.stdev(model_scores)\n",
    "    \n",
    "    print(\"mean and std: {}, {}\".format(mean, std))\n",
    "    \n",
    "    # Retrieve the index of the model with highest score.\n",
    "    highest_score_index = model_scores.index(max(model_scores))\n",
    "    \n",
    "    # Retrieve that model.\n",
    "    best_model = models[highest_score_index]\n",
    "    \n",
    "    # Predict on best model on this round.\n",
    "    y_pred_out = model.predict(X_test_out)\n",
    "    \n",
    "    # Show results\n",
    "    accuracy_out = accuracy_score(y_test_out, y_pred_out)\n",
    "    cm_out = classification_report(y_test_out, y_pred_out)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

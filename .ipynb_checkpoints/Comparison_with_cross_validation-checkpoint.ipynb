{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features: V1 ~ V28 and Amount\n",
    "# Select target: Class\n",
    "features = ['Amount'] + ['V%d' % index for index in range(1, 29)]\n",
    "target = 'Class'\n",
    "\n",
    "# raw data X and y\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize values for each feature, because there are many features with wide range of values\n",
    "# We need to get them in the equivalent range. Make the distribution of each values on the same scale.\n",
    "# Normalization procedure: (value - mean)/std\n",
    "# Normalization has to be done after split individually on both train and test sets.\n",
    "# Scaled data has zero mean and unit variance:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 train_indices_out [45 63 75 82 91 10]\n",
      "Round: 1 X_test_out [32 12 34 57]\n",
      "train_indices_in :d [34 45 57 63]\n",
      "test_indices_in :d [1 0 1 1]\n",
      "train_indices_in :d [32 12 45 63]\n",
      "test_indices_in :d [0 0 0 1]\n",
      "train_indices_in :d [32 12 34 57]\n",
      "test_indices_in :d [0 0 1 1]\n",
      " \n",
      "Round: 2 train_indices_out [32 12 34 57 82 10]\n",
      "Round: 2 X_test_out [45 63 75 91]\n",
      "train_indices_in :d [12 45 57 63]\n",
      "test_indices_in :d [0 0 1 1]\n",
      "train_indices_in :d [32 34 57 63]\n",
      "test_indices_in :d [0 1 1 1]\n",
      "train_indices_in :d [32 12 34 45]\n",
      "test_indices_in :d [0 0 1 0]\n",
      " \n",
      "Round: 3 train_indices_out [32 12 34 45 57 63 75 91]\n",
      "Round: 3 X_test_out [82 10]\n",
      "train_indices_in :d [45 63 75 82]\n",
      "test_indices_in :d [0 1 1 1]\n",
      "train_indices_in :d [32 12 34 57 75 82]\n",
      "test_indices_in :d [0 0 1 1 1 1]\n",
      "train_indices_in :d [32 12 34 45 57 63]\n",
      "test_indices_in :d [0 0 1 0 1 1]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 1. Define a model\n",
    "# 2. Stratified K-Folds cross-validator maintains percentage of samples for each class.\n",
    "# 3. Random_state = none ensures the results is replicable.\n",
    "# n_splits: how many times we want to split the data.\n",
    "\n",
    "# DT = DecisionTreeClassifier()\n",
    "# KNN = KNeighborsClassifier()\n",
    "# RFC = RandomForestClassifier()\n",
    "# ABC = AdaBoostClassifier()\n",
    "# SVM = SVC() \n",
    "i = 0\n",
    "\n",
    "X = np.array([32,12,34,45,57,63,75,82,91,10])\n",
    "y = np.array([0,0,1,0,1,1,1,1,0,0])\n",
    "# skf_out = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "skf = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "for train_indices_out, test_indices_out in skf.split(X,y):\n",
    "    i+=1\n",
    "    # train/test split - outer loop.\n",
    "    X_train_out = X[train_indices_out] \n",
    "    y_train_out = y[train_indices_out]\n",
    "    \n",
    "    X_test_out = X[test_indices_out]\n",
    "    y_test_out = y[test_indices_out]\n",
    "    \n",
    "    print(\"Round: {} train_indices_out {}\".format(i, X_train_out))\n",
    "    print(\"Round: {} X_test_out {}\".format(i, X_test_out))\n",
    "    \n",
    "#     skf_in = StratifiedKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "    for train_indices_in, test_indices_in in skf.split(X_train_out,y_train_out):\n",
    "        \n",
    "        # train/test split - inner loop.\n",
    "        X_train_in = X_train_out[train_indices_in] \n",
    "        y_train_in = y_train_out[train_indices_in]\n",
    "    \n",
    "        X_test_in = X_train_out[test_indices_in]\n",
    "        y_test_in = y_train_out[test_indices_in]\n",
    "        \n",
    "        print(\"train_indices_in :d\", X_train_in)\n",
    "        print(\"test_indices_in :d\",y_train_in)\n",
    "        \n",
    "    print(\" \")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features: V1 ~ V28 and Amount\n",
    "# Select target: Class\n",
    "features = ['Amount'] + ['V%d' % index for index in range(1, 29)]\n",
    "target = 'Class'\n",
    "\n",
    "# raw data X and y\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trick\n"
     ]
    }
   ],
   "source": [
    "# Normalize values for each feature, because there are many features with wide range of values\n",
    "# We need to get them in the equivalent range. Make the distribution of each values on the same scale.\n",
    "# Normalization procedure: (value - mean)/std\n",
    "# Normalization has to be done after split individually on both train and test sets.\n",
    "# Scaled data has zero mean and unit variance:\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# min_max_scalar = MinMaxScaler()\n",
    "def nomalization(X):\n",
    "    for feature in X.columns:\n",
    "        X[feature] -= X[feature].mean()\n",
    "        X[feature] /= X[feature].std()\n",
    "    return X\n",
    "print('trick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "0.999210006583\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.75      0.82      0.78        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.99916611806\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.78      0.72      0.75        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.977199411881\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.98      0.99     45490\n",
      "          1       0.06      0.84      0.11        79\n",
      "\n",
      "avg / total       1.00      0.98      0.99     45569\n",
      "\n",
      "0.998858848315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.65      0.72      0.68        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "0.999188026685\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.79      0.72      0.75        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "mean and std: 0.9947244823048579, 0.009797861505701281\n",
      "Round 2\n",
      "0.998573622998\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.55      0.90      0.69        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.998968619706\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.78      0.57      0.66        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.998068862604\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.46      0.70      0.56        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.999078300562\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.78      0.64      0.70        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "0.998946629213\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.72      0.63      0.67        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "mean and std: 0.9967258446607067, 0.006869688424236374\n",
      "Round 3\n",
      "0.968400263331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     45491\n",
      "          1       0.05      0.94      0.09        79\n",
      "\n",
      "avg / total       1.00      0.97      0.98     45570\n",
      "\n",
      "0.99929778363\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.81      0.77      0.79        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.99929776822\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.80      0.80      0.80        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.999100265531\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.74      0.75      0.74        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.999231917135\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.84      0.68      0.75        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "mean and std: 0.9955057629635755, 0.009372799068988564\n",
      "Round 4\n",
      "0.998200570551\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.49      0.84      0.62        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.999144173799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.76      0.73      0.75        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.998968597073\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.74      0.63      0.68        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.997366630824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.35      0.59      0.44        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.999078300562\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.74      0.72      0.73        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "mean and std: 0.996267235863047, 0.008166076650516373\n",
      "Round 5\n",
      "0.998507790213\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.55      0.80      0.65        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.999341672153\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45491\n",
      "          1       0.83      0.78      0.81        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45570\n",
      "\n",
      "0.999012486559\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.75      0.65      0.69        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.996203559437\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.26      0.63      0.37        79\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45569\n",
      "\n",
      "0.999034410112\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     45490\n",
      "          1       0.73      0.69      0.71        78\n",
      "\n",
      "avg / total       1.00      1.00      1.00     45568\n",
      "\n",
      "mean and std: 0.9966977854294029, 0.007337253624036996\n"
     ]
    }
   ],
   "source": [
    "# 1. Define a model\n",
    "# 2. Stratified K-Folds cross-validator maintains percentage of samples for each class.\n",
    "# 3. Random_state = none ensures the results is replicable.\n",
    "# n_splits: how many times we want to split the data.\n",
    "\n",
    "# We test on a series of models.\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "# model = KNeighborsClassifier()\n",
    "# model = RandomForestClassifier()\n",
    "# model = AdaBoostClassifier()\n",
    "# model = SVC() \n",
    "i = 0\n",
    "\n",
    "models = [] # to hold all the temporary models.\n",
    "model_scores = [] # to hold the accuracy scores \n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_indices_out, test_indices_out in skf.split(X, y):\n",
    "    i+=1\n",
    "    # train/test split - outer loop.\n",
    "    X_train_out = X.loc[train_indices_out] \n",
    "    y_train_out = y.loc[train_indices_out]\n",
    "    \n",
    "    X_test_out = X.loc[test_indices_out]\n",
    "    y_test_out = y.loc[test_indices_out]\n",
    "    \n",
    "    print(\"Round {}\".format(i))\n",
    "    \n",
    "    for train_indices_in, test_indices_in in skf.split(X_train_out, y_train_out):\n",
    "\n",
    "        # train/test split - inner loop.\n",
    "        X_train_in = X_train_out.iloc[train_indices_in] \n",
    "        y_train_in = y_train_out.iloc[train_indices_in]\n",
    "    \n",
    "        X_test_in = X_train_out.iloc[test_indices_in]\n",
    "        y_test_in = y_train_out.iloc[test_indices_in]\n",
    "        \n",
    "        # Fit\n",
    "        model.fit(X_train_in, y_train_in)\n",
    "    \n",
    "        # Add to the model list.\n",
    "        models.append(model)\n",
    "    \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_in)\n",
    "\n",
    "        # Show results\n",
    "        accuracy = accuracy_score(y_test_in, y_pred)\n",
    "        print(accuracy)\n",
    "        model_scores.append(accuracy)\n",
    "        cm = classification_report(y_test_in, y_pred)\n",
    "        print(cm)\n",
    "    \n",
    "    # Calculate the mean and std_dev of the accuracy scores.\n",
    "    mean = statistics.mean(model_scores)\n",
    "    std = statistics.stdev(model_scores)\n",
    "    \n",
    "    print(\"mean and std: {}, {}\".format(mean, std))\n",
    "    \n",
    "    # Retrieve the index of the model with highest score.\n",
    "    highest_score_index = model_scores.index(max(model_scores))\n",
    "    \n",
    "    # Retrieve that model.\n",
    "    best_model = models[highest_score_index]\n",
    "    \n",
    "    print(\"highest score: \".format(max(model_scores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
